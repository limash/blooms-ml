{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgaHaBA4pFW0"
      },
      "source": [
        "## Check / Prepare data for algae blooms identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kb2N9DLdKmQ"
      },
      "source": [
        "\n",
        "The idea is to take the modeled data and train a machine learning (ML) model on that data, then try to use on the observational data.\n",
        "The reason - models can't predict very well the exact time and location of algae blooms but they reproduce the physics/biogeochemistry of it.\n",
        "Thus, the intuition to check is that a ML model trained on modelled data will be able to predict blooms on observational data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VetmTphZWE-t"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np  # noqa: F401\n",
        "import pandas as pd  # noqa: F401\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt  # noqa: F401\n",
        "\n",
        "from blooms_ml.utils import (\n",
        "    extract_stations_rho,\n",
        "    extract_stations_u,\n",
        "    extract_stations_v,\n",
        "    merge_edges_to_centers,\n",
        "    append_rho_profiles,\n",
        "    plot_variable,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ze_WckQlFgP"
      },
      "source": [
        "There is the output of hydrophysical+biogeochemical model of the Hardangerfjord at HPC FRAM.\n",
        "The files are very huge to download, so I have just mounted a data folder to use them.\n",
        "This is based on the ROMS hydrophysical and NERSEM biogeochemical models.\n",
        "Diagnostic files have data about PAR (photosynthetically active radiation).\n",
        "'Average' files have the rest of the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files_dia = sorted(glob.glob(f\"{Path.home()}/fram_shmiak/ROHO800_hindcast_2007_2019_v2bu/roho800_v2bu_dia/*dia*.nc\"))\n",
        "files_avg = sorted(glob.glob(f\"{Path.home()}/fram_shmiak/ROHO800_hindcast_2007_2019_v2bu/roho800_v2bu_avg/*avg*.nc\"))\n",
        "last_n_files = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Bzl-FfV0en"
      },
      "outputs": [],
      "source": [
        "ds_dia = xr.open_mfdataset(files_dia[-last_n_files:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "st_labels = ['1', '2', '3', '4']\n",
        "xis = [100, 120, 140, 160]\n",
        "etas = [100, 110, 120, 130]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = ds_dia.mask_rho.isel(ocean_time=-1).plot(\n",
        "    x=\"xi_rho\", y=\"eta_rho\", figsize=(14, 7), cmap='GnBu'\n",
        "    )\n",
        "p.axes.scatter(x=xis, y=etas, color='red')\n",
        "for i, label in enumerate(st_labels):\n",
        "    p.axes.annotate(label, (xis[i], etas[i]), color='red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract light from the chosen points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = extract_stations_rho(ds_dia, xis, etas)\n",
        "ds = merge_edges_to_centers(ds)\n",
        "df_dia = ds[['light_PAR0', 'P1_netPI']].to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPWnLmJEiJ6W"
      },
      "source": [
        "Extract other variables.\n",
        "There are too many variables, let's take only some of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZed2-5XZdJ6"
      },
      "outputs": [],
      "source": [
        "vars = ['lat_rho', 'lon_rho', 'ocean_time', 's_rho',\n",
        "        'TotChl', 'P1_c',\n",
        "        'swradWm2',\n",
        "        'rho', 'temp', 'salt', 'AKv', 'u', 'v', 'w',\n",
        "        'N1_p', 'N3_n', 'N5_s', 'O2_o']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds_avg = xr.open_mfdataset(files_avg[-last_n_files:])\n",
        "ds_rho = extract_stations_rho(ds_avg, xis, etas)\n",
        "ds_rho = ds_rho.drop_dims(['eta_u', 'eta_v', 'eta_psi', 'xi_u', 'xi_v', 'xi_psi' ])\n",
        "ds_u = extract_stations_u(ds_avg, xis, etas)\n",
        "ds_u = ds_u.drop_dims(['eta_rho', 'eta_v', 'eta_psi', 'xi_rho', 'xi_v', 'xi_psi' ])\n",
        "ds_v = extract_stations_v(ds_avg, xis, etas)\n",
        "ds_v = ds_v.drop_dims(['eta_rho', 'eta_u', 'eta_psi', 'xi_rho', 'xi_u', 'xi_psi' ])\n",
        "ds = xr.merge([ds_rho, ds_u, ds_v])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = merge_edges_to_centers(ds)\n",
        "ds_subset = ds.drop_vars([var for var in ds.variables if var not in vars])\n",
        "df = ds_subset.to_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['light_PAR0'] = df_dia['light_PAR0']\n",
        "df['P1_netPI'] = df_dia['P1_netPI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_station = df.loc[df.index.get_level_values('station') == 3]\n",
        "df_station = df_station.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_station"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='light_PAR0').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVU7nKPvI1_p"
      },
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='P1_c').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='P1_netPI').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='w').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ8g49u8doWi"
      },
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='rho').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjuKnb-rGH_j"
      },
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='N1_p').iloc[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0GTxQkdGI9A"
      },
      "outputs": [],
      "source": [
        "plot_variable(df_station.pivot(index='s_rho', columns='ocean_time', values='N3_n').iloc[::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing.\n",
        "Using equation of state it is possible to recover density form temperature and salinity.\n",
        "Extract and append rho profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input = df.drop(columns=['lon_rho', 'lat_rho', 'temp', 'salt', 'u', 'v', 'O2_o', 'AKv'])\n",
        "df_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input['rho'] = scaler.fit_transform(df_input['rho'].values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input = append_rho_profiles(df_input)\n",
        "df_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# no light, no blooms, remove dark points, it will help with scaling and sampling\n",
        "df_input = df_input[df_input['light_PAR0'] > 10].reset_index(drop=True)\n",
        "df_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input = df_input.drop(columns=['ocean_time', 's_rho'])\n",
        "df_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input.iloc[:, :8] = scaler.fit_transform(df_input.iloc[:, :8].values)\n",
        "df_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_input.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
